{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05155f2-ee68-4482-b4f9-0036f4ae692d",
   "metadata": {},
   "source": [
    "# Simple LangGraph Agent with Tool Calling\n",
    "\n",
    "This notebook demonstrates how you can create a simple LangGraph agent with tool calling capabilities.  \n",
    "LangSmith traces are provided with the test runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5caae2a-84f7-470a-9f2f-27f0521dd827",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lalanikarim/notebooks/blob/main/LangGraph-MessageGraph-OllamaFunctions.ipynb)\n",
    "\n",
    "## Install and run Ollama\n",
    "\n",
    "For this lab we will download and run Ollama locally and use the `phi3` model for tool calling.  \n",
    "Adjust the below commands for your local environment.  \n",
    "This code is tested to work within Google Colab using the free tier T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9afc73-6a43-47a9-940c-a9ddcd238714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "ollama serve &> ollama.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b2e5b-b7e0-446c-b712-695337e51875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!until ollama list; do echo waiting for ollama; sleep 5; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaf8db-2dfd-495b-bd2a-18c428e18dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "ollama pull phi3 >> phi3.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fc6df-c943-49d2-b284-c426e009f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!until ollama list | grep phi3; do echo waiting for phi; sleep 5; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94e2ba-c5d0-4464-9d5f-4c6bfd03a28a",
   "metadata": {},
   "source": [
    "## Install Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb07f6a-8877-4626-9297-b8f6966f1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-core==0.2.5 langchain-community==0.2.4 langgraph==0.0.66 duckduckgo-search==6.1.5 httpx\n",
    "%pip install git+https://github.com/lalanikarim/langchain.git@convert-to-ollama-tool\\#egg=langchain-experimental\\&subdirectory=libs/experimental\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2a23e-ec5e-4a6b-8317-37292398d7a8",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "425cdcdd-3cb2-408f-90bb-655e3413d37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"from langchain_core.tools import tool\\nfrom langchain_experimental.llms.ollama_functions import OllamaFunctions\\nfrom langgraph.graph import MessageGraph, END\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain_community.tools import DuckDuckGoSearchRun\\nfrom IPython.display import display, HTML, Image\\nfrom langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\\nfrom typing import List\\nimport os\";\n",
       "                var nbb_formatted_code = \"from langchain_core.tools import tool\\nfrom langchain_experimental.llms.ollama_functions import OllamaFunctions\\nfrom langgraph.graph import MessageGraph, END\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain_community.tools import DuckDuckGoSearchRun\\nfrom IPython.display import display, HTML, Image\\nfrom langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\\nfrom typing import List\\nimport os\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langgraph.graph import MessageGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from IPython.display import display, HTML, Image\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from typing import List\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644620b7-3d88-4bb5-b3c7-89ecd8f05a80",
   "metadata": {},
   "source": [
    "## (Optional) Environment variables for LangSmith tracing\n",
    "\n",
    "Uncomment the code in the below cell and add your LangSmith API key to enable tracing within LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "935bfd6d-69b5-4795-8599-452942d653ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"# os.environ[\\\"LANGCHAIN_API_KEY\\\"] = \\\"xxx\\\"\\n# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n# os.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Simple Tool Calling\\\"\";\n",
       "                var nbb_formatted_code = \"# os.environ[\\\"LANGCHAIN_API_KEY\\\"] = \\\"xxx\\\"\\n# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n# os.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Simple Tool Calling\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"xxx\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"Simple Tool Calling\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12717f0-be3f-4b01-a576-b70031886d2c",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Here we have created 4 custom tools and used an existing tool for our toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90ca0dde-f220-4f8e-a8c0-be74e6bdcfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"@tool\\ndef multiply(a: int, b: int) -> int:\\n    \\\"\\\"\\\"Tool to multiply two numbers\\\"\\\"\\\"\\n    return a * b\\n\\n\\n@tool\\ndef add(a: int, b: int) -> int:\\n    \\\"\\\"\\\"Tool to add two numbers\\\"\\\"\\\"\\n    return a + b\\n\\n\\n@tool\\ndef call_miracle(request: str) -> str:\\n    \\\"\\\"\\\"Tool to call miracle\\\"\\\"\\\"\\n    return f\\\"You asked for {request}, but I can't do that\\\"\\n\\n\\n@tool\\ndef grant_wish(wish: str) -> str:\\n    \\\"\\\"\\\"Tool to grant wish\\\"\\\"\\\"\\n    return f\\\"You asked for {wish}. Your wish is my command!\\\"\\n\\n\\ntools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\\n\\n# tool_node will be used as a node within the LangGraph agent\\ntool_node = ToolNode(tools)\";\n",
       "                var nbb_formatted_code = \"@tool\\ndef multiply(a: int, b: int) -> int:\\n    \\\"\\\"\\\"Tool to multiply two numbers\\\"\\\"\\\"\\n    return a * b\\n\\n\\n@tool\\ndef add(a: int, b: int) -> int:\\n    \\\"\\\"\\\"Tool to add two numbers\\\"\\\"\\\"\\n    return a + b\\n\\n\\n@tool\\ndef call_miracle(request: str) -> str:\\n    \\\"\\\"\\\"Tool to call miracle\\\"\\\"\\\"\\n    return f\\\"You asked for {request}, but I can't do that\\\"\\n\\n\\n@tool\\ndef grant_wish(wish: str) -> str:\\n    \\\"\\\"\\\"Tool to grant wish\\\"\\\"\\\"\\n    return f\\\"You asked for {wish}. Your wish is my command!\\\"\\n\\n\\ntools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\\n\\n# tool_node will be used as a node within the LangGraph agent\\ntool_node = ToolNode(tools)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def call_miracle(request: str) -> str:\n",
    "    \"\"\"Tool to call miracle\"\"\"\n",
    "    return f\"You asked for {request}, but I can't do that\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def grant_wish(wish: str) -> str:\n",
    "    \"\"\"Tool to grant wish\"\"\"\n",
    "    return f\"You asked for {wish}. Your wish is my command!\"\n",
    "\n",
    "\n",
    "tools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\n",
    "\n",
    "# tool_node will be used as a node within the LangGraph agent\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9bc53-68c8-47f8-9e7f-a49de94568f6",
   "metadata": {},
   "source": [
    "## Initialize LLM and bind tools\n",
    "\n",
    "You can use any tool calling capable LLM along with a model that offers good JSON support.  \n",
    "We have use `OllamaFunctions` with the `phi3` model here.  \n",
    "The complete list of natively supported [LLMs with tool calling can be found here](https://python.langchain.com/v0.1/docs/integrations/chat/)  \n",
    "\n",
    "We initialize `llm` and add tools description on it by calling `bind_tools` function on it.  \n",
    "This doesn't change `llm` itself, but returns a new LLM object that is aware of the tools specifications which we store as `llm_with_tools`.  \n",
    "\n",
    "We will use `llm_with_tools` for any tool aware LLM calls and use `llm` for other, non tool related LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb412514-ec62-44ae-909e-afab0de0aada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"llm = OllamaFunctions(model=\\\"phi3\\\", format=\\\"json\\\", temperature=0)\\nllm_with_tools = llm.bind_tools(tools)\";\n",
       "                var nbb_formatted_code = \"llm = OllamaFunctions(model=\\\"phi3\\\", format=\\\"json\\\", temperature=0)\\nllm_with_tools = llm.bind_tools(tools)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14777d-5d5f-4702-9c41-d962fbe0657c",
   "metadata": {},
   "source": [
    "## MessageGraph\n",
    "\n",
    "[MessageGraph](https://python.langchain.com/v0.1/docs/integrations/chat/) is a simple `LangGraph` state type where every node receives a list of messages as input and returns one or more messages as output.  \n",
    "\n",
    "This should be suitable for may use cases where you only need to track messages as part of the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92f699f8-6b18-4091-a36c-f0353d8677e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"builder = MessageGraph()\";\n",
       "                var nbb_formatted_code = \"builder = MessageGraph()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = MessageGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b16ee-5a90-4b2b-8c64-217f294b4ae1",
   "metadata": {},
   "source": [
    "## Add nodes to graph\n",
    "\n",
    "Graph nodes have a name and take a callables as a second argument which are runnables that get invoked and are passed the entire state object.  \n",
    "\n",
    "Since `MessageGraph` is essentially just a collection of messages, you can use LLMs as the callable parameter.  \n",
    "\n",
    "* `oracle`: We pass `llm_with_tools` as this node with identify which tool needs to be called to complete the current request.\n",
    "* `tools`: We pass `tool_node` as the callable. If the last message in the state is an `AIMessage` with `tool_calls`, this node will use that information to call the approprtate tool from our toolset with the parameters specified in `tool_calls`.\n",
    "* `llm`: We pass `llm` as the callable. This node will take all the messages generated thus far and use that context to generate a new message. The expected outcome is the model's interpretation of the results from the tool run within the context of the initial question that was asked of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c98683d-a279-4f64-b8cb-f7dc9e6d61c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"builder.add_node(\\\"oracle\\\", llm_with_tools)\\nbuilder.add_node(\\\"tools\\\", tool_node)\\nbuilder.add_node(\\\"llm\\\", llm)\";\n",
       "                var nbb_formatted_code = \"builder.add_node(\\\"oracle\\\", llm_with_tools)\\nbuilder.add_node(\\\"tools\\\", tool_node)\\nbuilder.add_node(\\\"llm\\\", llm)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder.add_node(\"oracle\", llm_with_tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_node(\"llm\", llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2652e-c05e-4b61-824f-c38630688b46",
   "metadata": {},
   "source": [
    "## Connect agent nodes with edges\n",
    "\n",
    "This will be a simple linear graph.\n",
    "\n",
    "* `oracle` is the entry point.\n",
    "* `tools` node will be called after `oracle`.\n",
    "* `llm` node will be called after `tools`.\n",
    "* graph ends with the execution of `llm` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da62f02d-da29-4aad-b0b7-c26f44005d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"builder.add_edge(\\\"oracle\\\", \\\"tools\\\")\\nbuilder.add_edge(\\\"tools\\\", \\\"llm\\\")\\nbuilder.add_edge(\\\"llm\\\", END)\\nbuilder.set_entry_point(\\\"oracle\\\")\\ngraph = builder.compile()\";\n",
       "                var nbb_formatted_code = \"builder.add_edge(\\\"oracle\\\", \\\"tools\\\")\\nbuilder.add_edge(\\\"tools\\\", \\\"llm\\\")\\nbuilder.add_edge(\\\"llm\\\", END)\\nbuilder.set_entry_point(\\\"oracle\\\")\\ngraph = builder.compile()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder.add_edge(\"oracle\", \"tools\")\n",
    "builder.add_edge(\"tools\", \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "builder.set_entry_point(\"oracle\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd2f6a-f94b-4f2f-b75a-1d975415c658",
   "metadata": {},
   "source": [
    "## Visualizing the graph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "280a24c9-c753-4149-8ccb-3ea2b79c5c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"display(\\n    Image(\\n        graph.get_graph().draw_mermaid_png()\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"display(Image(graph.get_graph().draw_mermaid_png()))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd380bd3-ab9a-4619-8f3d-22d29d67e909",
   "metadata": {},
   "source": [
    "## Pretty print messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db2a447e-fe52-4d70-bc65-5f2e1f763196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"def trim_content(content: str) -> str:\\n    if len(content) < 200:\\n        return content\\n    else:\\n        return content[:200] + \\\"...\\\"\\n\\n\\ndef pretty_print(message: BaseMessage):\\n    print(f\\\"type: {message.type}\\\", end=\\\"\\\")\\n    if isinstance(message, AIMessage) and message.tool_calls:\\n        print(f\\\", tool_calls: {message.tool_calls}\\\", end=\\\"\\\")\\n    elif isinstance(message, ToolMessage):\\n        print(f\\\", name: {message.name}\\\", end=\\\"\\\")\\n    if message.content:\\n        print(f\\\", content: {trim_content(message.content)}\\\", end=\\\"\\\")\\n    print(\\\"\\\\n\\\")\\n\\n\\ndef pretty_print_messages(messages: List[BaseMessage]):\\n    [pretty_print(message) for message in messages]\";\n",
       "                var nbb_formatted_code = \"def trim_content(content: str) -> str:\\n    if len(content) < 200:\\n        return content\\n    else:\\n        return content[:200] + \\\"...\\\"\\n\\n\\ndef pretty_print(message: BaseMessage):\\n    print(f\\\"type: {message.type}\\\", end=\\\"\\\")\\n    if isinstance(message, AIMessage) and message.tool_calls:\\n        print(f\\\", tool_calls: {message.tool_calls}\\\", end=\\\"\\\")\\n    elif isinstance(message, ToolMessage):\\n        print(f\\\", name: {message.name}\\\", end=\\\"\\\")\\n    if message.content:\\n        print(f\\\", content: {trim_content(message.content)}\\\", end=\\\"\\\")\\n    print(\\\"\\\\n\\\")\\n\\n\\ndef pretty_print_messages(messages: List[BaseMessage]):\\n    [pretty_print(message) for message in messages]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def trim_content(content: str) -> str:\n",
    "    if len(content) < 200:\n",
    "        return content\n",
    "    else:\n",
    "        return content[:200] + \"...\"\n",
    "\n",
    "\n",
    "def pretty_print(message: BaseMessage):\n",
    "    print(f\"type: {message.type}\", end=\"\")\n",
    "    if isinstance(message, AIMessage) and message.tool_calls:\n",
    "        print(f\", tool_calls: {message.tool_calls}\", end=\"\")\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        print(f\", name: {message.name}\", end=\"\")\n",
    "    if message.content:\n",
    "        print(f\", content: {trim_content(message.content)}\", end=\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: List[BaseMessage]):\n",
    "    [pretty_print(message) for message in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe6838-4fa0-4b9f-956b-8f8a6c6d492d",
   "metadata": {},
   "source": [
    "## Running the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76b7c412-df73-49e0-a00a-a7c05e2aa4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is the sum of 2 and 3?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_226e4ac1daff4d5e81094a7241bea4a4'}]\n",
      "\n",
      "type: tool, name: add, content: 5\n",
      "\n",
      "type: ai, content: The sum of 2 and 3 is 5.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"result = graph.invoke((\\\"human\\\", \\\"What is the sum of 2 and 3?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_formatted_code = \"result = graph.invoke((\\\"human\\\", \\\"What is the sum of 2 and 3?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is the sum of 2 and 3?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea842a2c-ee9e-46b6-af0b-a3399c541953",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/c5891130-d869-4f57-ab98-a9a264d6d524/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "38fec4c8-91aa-42a4-9685-35a3f8705eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is 523 x 412?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'multiply', 'args': {'a': 523, 'b': 412}, 'id': 'call_3b82eb39ee33477f868733faca218921'}]\n",
      "\n",
      "type: tool, name: multiply, content: 215476\n",
      "\n",
      "type: ai, content: The result of multiplying 523 by 412 is 215,476.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"result = graph.invoke((\\\"human\\\", \\\"What is 523 x 412?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_formatted_code = \"result = graph.invoke((\\\"human\\\", \\\"What is 523 x 412?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is 523 x 412?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ad7b9-0fc3-4d7b-b34a-476806fdb517",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/ca3b89f1-be50-4bda-8622-fd2ba8429230/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba663f2b-0255-4a23-9094-67f139b281f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I need a miracle. I need it to rain tomorrow.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'call_miracle', 'args': {'request': 'I need a miracle that it will rain tomorrow.'}, 'id': 'call_0ef02bc563e94c5992182084c3a4939d'}]\n",
      "\n",
      "type: tool, name: call_miracle, content: You asked for I need a miracle that it will rain tomorrow., but I can't do that\n",
      "\n",
      "type: ai, content: I understand you're hoping for some rain, but unfortunately, as an AI, I don't have the ability to influence weather patterns. However, I can help find local forecasts if that would be helpful!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 81;\n",
       "                var nbb_unformatted_code = \"result = graph.invoke((\\\"human\\\", \\\"I need a miracle. I need it to rain tomorrow.\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_formatted_code = \"result = graph.invoke((\\\"human\\\", \\\"I need a miracle. I need it to rain tomorrow.\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I need a miracle. I need it to rain tomorrow.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5e6e8-64a0-407a-93ef-eca730359c31",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/de7c375d-c0e8-49dd-9042-553d3e460451/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e805096e-a9cc-4ffc-8569-7eaa5ae4cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I wish for world peace.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'grant_wish', 'args': {'wish': 'I wish for world peace.'}, 'id': 'call_0fc39accad1d4e4fa896ed14711828d9'}]\n",
      "\n",
      "type: tool, name: grant_wish, content: You asked for I wish for world peace.. Your wish is my command!\n",
      "\n",
      "type: ai, content: I share your sentiment and hope that one day we can all live in a more peaceful world.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 82;\n",
       "                var nbb_unformatted_code = \"result = graph.invoke((\\\"human\\\", \\\"I wish for world peace.\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_formatted_code = \"result = graph.invoke((\\\"human\\\", \\\"I wish for world peace.\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I wish for world peace.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d242bb-da18-4a4d-bf82-74076d49733f",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/8054cbb8-d59c-4cfc-b0ce-11b74d81f5ac/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ae68d5d-9774-4319-9ed7-603d7ed440a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: Can you make it snow?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'call_miracle', 'args': {'request': 'Can you make it snow?'}, 'id': 'call_75c9648f03594141a36a0239599a4458'}]\n",
      "\n",
      "type: tool, name: call_miracle, content: You asked for Can you make it snow?, but I can't do that\n",
      "\n",
      "type: ai, content: I'm afraid I can't control the weather, but I hope it snows soon!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"result = graph.invoke((\\\"human\\\", \\\"Can you make it snow?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_formatted_code = \"result = graph.invoke((\\\"human\\\", \\\"Can you make it snow?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"Can you make it snow?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9982e5-6e21-496c-b13f-42e532fae3ef",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/e923931d-dce8-421d-851a-5842d340aed7/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a238c49e-a7ed-4354-8478-eaee5a6be937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is tomorrows weather in Austin, TX?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'duckduckgo_search', 'args': {'query': \"tomorrow's weather in Austin, Texas\"}, 'id': 'call_884cc9aef2584e3aa98165a3b84bcaec'}]\n",
      "\n",
      "type: tool, name: duckduckgo_search, content: Get the latest weather forecast for Austin, TX, with critical fire weather concerns, unsettled conditions and severe weather risks. Weather forecast and weather maps for tomorrow at Austin, Texas, USA...\n",
      "\n",
      "type: ai, content: Let me find that information for you.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 84;\n",
       "                var nbb_unformatted_code = \"result = graph.invoke((\\\"human\\\", \\\"What is tomorrows weather in Austin, TX?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_formatted_code = \"result = graph.invoke((\\\"human\\\", \\\"What is tomorrows weather in Austin, TX?\\\"))\\npretty_print_messages(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is tomorrows weather in Austin, TX?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fd4d0-e757-45cd-b0a7-80e9179800ed",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/2c6b59d8-0611-46b2-8851-1140382587e2/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
